# Copyright (C) 2010 McAfee, Inc. All rights reserved
import subprocess
import sys
import os
import logging
import re
import shutil
import time

# Add common folder into the sys path for module importing
sys.path.append("../Common")
import commonFns
import commonOASFns
import LinuxShieldConfigParser
###########################################################################
# Constants used in the functions.
###########################################################################
NAILS_SERVICES = ['scanner', 'nailsd', 'nailswebd', 'mon', 'logepo', 'nailslogd']
ANTIMALWARE_SERVICES = NAILS_SERVICES + ['cma']
SQLITE       = '/opt/NAI/LinuxShield/libexec/sqlite'
NAILS        = '/opt/NAI/LinuxShield/bin/nails'
NAILS_CONFIG = '/var/opt/NAI/LinuxShield/etc/nailsd.cfg'
NAILS_INITD  = '/etc/init.d/nails'
DAT_PATH     = '/opt/NAI/LinuxShield/engine/dat'
NAILS_DB     = '/var/opt/NAI/LinuxShield/etc/nailsd.db' 
ODS_CONFIG  = '/var/opt/NAI/LinuxShield/etc/ods.cfg'
PRODUCT_PATHS = ['/opt/NAI/LinuxShield','/var/opt/NAI/LinuxShield','/etc/init.d/nails','/opt/McAfee/cma',
                 '/lib/ld-mfert.so.2', '/lib/ld-nails.so.2'] 
SCHEMA_EVENTLOG = ['i_logId', 'origin', 'i_taskId', 'i_objId', 'i_tim', 'errorClsNm', 'i_errorCode', 'errorType',
                   'description']
SCHEMA_SCHEDULE = ['i_taskId', 'taskName', 'timetable', 'taskType', 'taskInfo', 'taskResults', 'i_lastRun', 'status',
        'progress', 'i_duration', 'i_nextRun', 'i_recurrenceCounter', 'i_taskPid']
SCHEMA_SCANLOG  = [ 'i_logId', 'origin', 'i_taskId', 'i_objId', 'i_tim', 'fileName', 'path', 'action', 'virusName', 
        'virusType', 'userName', 'processName' ]
VALID_ACTIONS = ['Clean', 'Quarantine', 'Delete', 'Block', 'Rename']
MD5_FILE_PATH   = '/opt/NAI/LinuxShield/etc/md5'
VALID_VSEL_KEYS = ['LYNXSHLD1500', 'LYNXSHLD1510', 'LYNXSHLD1600', 'LYNXSHLD1700']
MSA_CONFIG_PATH = '/opt/McAfee/cma/bin/msaconfig'
EPO_KEYS_REQUIRED_FILES = ['reqseckey.bin', 'SiteList.xml', 'srpubkey.bin'] 
VSEL_ID_VERSION_MAP = {
    'LYNXSHLD1500' : {
        'VSEL_VERSION' : '1.5.0', 
    },
    'LYXSHLD1510' : {
        'VSEL_VERSION' : '1.5.1',
        'MA_VERSION' : '4.0.0', # TODO
        'MA_PROD_ID' : 'EPOAGENT3700LYNX', # TODO
    },
    'LYNXSHLD1600' : {
        'VSEL_VERSION' : '1.6.0',
        'MA_VERSION' : '4.5.0', # TODO
        'MA_PROD_ID' : 'EPOAGENT3700LYNX', # TODO

    },
    'LYNXSHLD1700' : {
        'VSEL_VERSION' : '1.7.0',
        'MA_VERSION' : '4.5.0', # TODO
        'MA_PROD_ID' : 'EPOAGENT3700LYNX', # TODO
    },
}

def upgradeTo(package_files, current_version) :
    """
    Function to upgrade using the given packages
    param : package_files - list of package files (mfert, mfecma and mcafeevsel..*) 
    current_vesion : currently installed version.
    """

    # If LinuxShield 1.5.0 then uninstall NWA 
    
    logging.debug("Checking if LinuxShield 1.5.0 is installed")
    if current_version == VALID_VSEL_KEYS[0] :
        logging.debug("Uninstalling NWA");
        if not commonFns.UnInstall('NWA') :
            logging.error("Failed to uninstall NWA")
            return False
        # Now install (not upgrade) mfert and ma package.
        logging.debug("Installing %s" % package_files[0])
        if not commonFns.install(package_files[0]) :
            logging.error("Failed to install " + package_files[0])
            return False
        logging.debug("Installing %s" % package_files[1])
        if not commonFns.install(package_files[1]) :
            logging.error("Failed to install " + package_files[1])
            return False
        logging.debug("Installing %s" % package_files[2])
        if not commonFns.upgradeTo(package_files[2]) :
            logging.error("Failed to upgrade to " + package_files[2])
            return False
        logging.info("Successfully upgraded all packages")
        return True 

    # For other versions we can run upgarde.
    for package in package_files :
        logging.debug("Upgrading packages %s" % package)
        if not commonFns.upgradeTo(package) :
            logging.error("Failed to upgrade : " + package)
            return False  
    return True

def getBuildFileName(build_loc, version) :
    """
    Function to return the build file from the location, according to version specified and
    architecture of the machine.
    
    """
    if not os.path.isdir(build_loc) :
        logging.error("%s must be a directory containing the build" % build_loc)
        return None
    regex = '^McAfeeVSEForLinux-\d\.\d\.\d-\d+-release\.noarch(\.tar)?\.gz$'

    # For 1.5 and 1.5.1 we need to take builds as per the architecture 32 bit / 64 bit
    if VALID_VSEL_KEYS.index(version) < 2 :
        regex = '^LinuxShield-\d\.\d\.\d-\d+-release\.i386\.gz$'
        if re.search('64', os.uname()[4]) :
            regex = '^LinuxShield-\d\.\d\.\d-\d+-release\.x86_64\.gz$'
    logging.debug("Checking for file matching the regular expression %s in directory %s" % (regex, build_loc))
    entries = os.listdir(build_loc)
    for entry in entries :
        logging.debug("Checking %s" % entry)
        if re.search(regex, entry) :
             return build_loc + '/' + entry
    return None



def  getMD5Dict() :
    """
    Fn to read the MD5_FILE_PATH and return a dictionary object.
    """
    if not os.path.isfile(MD5_FILE_PATH) :
        logging.error("MD5 file %s does not exist" % MD5_FILE_PATH)
        return None
    md5fh = open(MD5_FILE_PATH, 'rb')
    md5lines = md5fh.readlines()
    md5fh.close()
    md5hash = dict()
    for line in md5lines :
        m = re.match('([\dabcdef]{32})\s+(.*)\n$', line)
        if m is not None :
            md5hash[m.group(2)] = m.group(1)
    return md5hash

def compareMD5(md5hash) :
    """
    Fn to compare the given hash of file:md5 with md5 of the file in the filesystem.
    """
    for filename in md5hash.keys() :
        if not os.path.exists(filename) :
            logging.warn("File %s is not found." % filename)
            next
        hashValue = getMD5ForFile(filename, False)

        if hashValue != md5hash[filename] :
            logging.error("MD5 Failed for File : %s [ Expected - %s, Actual  - %s ] " % (filename, md5hash[filename], hashValue))
            return False
    logging.info("Completed md5 comparison successfully")
    return True

def setManagedModeOff() :
    """
    Fn to switch to un-managed mode.
    """
    try :
        cmd = [MSA_CONFIG_PATH, '-u']
        logging.debug("Running command : " + ' '.join(cmd))
        retval = subprocess.call(cmd)
        if retval != 0:
            logging.error("Command returned with exit status %s " % retval)
            return False
        return True
    except :
        logging.error("Exception occured running the cma command for managed mode")
        return False

def setManagedModeOn(path) :
    """
    Fn to Switch to managed mode.
    """
    if not os.path.isdir(path) :
        logging.error("%s must be a directory" % path)
        return False
    entries = os.listdir(path)
    count = 0
    logging.debug("Checking if %s contains files %s" % (path, ','.join(EPO_KEYS_REQUIRED_FILES)))
    for entry in entries :
        if entry in EPO_KEYS_REQUIRED_FILES  :
           count = count + 1
    if count != len(EPO_KEYS_REQUIRED_FILES) :
        logging.error("One or more required files are missing")
        return False
    try :
        cmd = [MSA_CONFIG_PATH, '-m', '-d', path]
        logging.debug("Running command : " + ' '.join(cmd))
        retval = subprocess.call(cmd)
        if retval != 0:
            logging.error("Command returned with exit status %s " % retval)
            return False
        return True
    except :
        logging.error("Exception occured running the cma command for managed mode")
        return False

def isLinuxShieldKernelModuleLoaded() :
    """
    Fn to check if the linuxshield kernel module are loaded.
    """
    try :
        _p = subprocess.Popen(['lsmod'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if _p is None :
            logging.error('Unable to create process')
            return False
        _p.wait()
        _lines = _p.stdout.readlines()
        _lshook = False
        _linux = False
        for _line in _lines :
            if re.search('^linuxshield', _line) is not None :
                _linux = True
            if re.search('^lshook', _line) is not None :
                _lshook = True
            if _lshook and _linux :
                return True
    except :
        logging.error('isLinuxShieldKernelModuleLoaded failed with exception')
        return False
    kernel_version = commonFns.getKernelVerion()
    args = [kernel_version, False]
    os.path.walk(LS_MODULES_DIR, _matchKernelVersion, args)
    return args[1]

def _matchKernelVersion(args, dirname, fnames) :
    """
    Private fn to check if linuxshield kernel module matching with kernel version is available.
    """
    _kernel_version = args[0]
    for fname in fnames :
        if re.search(_kernel_version, fname) is not None and re.search('linuxshield', fname) is not None :
            args[1] = True
            break


def nailsStart() :
    """
    Fn to start nails.
    """
    if _nailsCmd('start') :
        logging.debug("Sleeping for 60 sec to let services come up")
        time.sleep(60)
        time_elapsed = 0
        logging.debug("Waiting for services to come up. Timeout is 300 seconds")
        while (time_elapsed < 300 ) :
            if areAllNailsServicesRunning() :
                return True
            time_elapsed = time_elapsed + 15
            time.sleep(2)
        return areAllNailsServicesRunning()
    return False

def nailsStop() :
    """
    Fn to stop nails service
    """
    if _nailsCmd('stop') :
        time_elapsed = 0
        while (time_elapsed < 180 ) :
            if not _isAnyServiceRunning() :
                return True
            time_elapsed = time_elapsed + 5
            time.sleep(5)
        return not _isAnyServiceRunning()
    return False

def nailsReload() :
    """
    Fn to reload the nails.
    """
    retval = _nailsCmd('reload')
    if retval == 0 :
        logging.debug("Sleeping for 120 seconds to let nails settle down")
        time.sleep(120)
    return retval

def nailsStatus() :
    """
    Fn to return status the nails
    @return - True on success. False otherwise.
    """
    try :
        _cmd = [NAILS_INITD, option]
        _p = subprocess.Popen(_cmd,  stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if _p is None:
            logging.error("Failed to create Popen object on nails")
            return False
        _p.wait()
        if _p.returncode != 0 :
            logging.error("nails %s failed with return code %s " % (option, _p.returncode))
            return False
        _lines = _p.stdout.readlines()
        _status = {'monitor':False, 'apache' : False, 'daemon' : False}
        for _line in _lines :
            if re.search('monitor gateway is running', _line, flag=re.IGNORECASE ) is not None :
                _status['monitor'] = True
            if re.search('Apache server is running', _line, flag=re.IGNORECASE ) is not None :
                _status['apache'] = True
            if re.search('daemon is running', _line, flag=re.IGNORECASE) is not None :
                _status['daemon'] = True
        return _status['daemon'] and _status['apache'] and _status['monitor']
    except :
        logging.error("'%s' failed with exception" % option)
        return False


def _nailsCmd(option) :
    """
    Fn to reload the nails
    @return - True on success. False otherwise.
    """
    try :
        _cmd = [NAILS_INITD, option]
        _p = subprocess.Popen(_cmd,  stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if _p is None:
            logging.error("Failed to create Popen object on nails")
            return False
        _p.wait()
        if _p.returncode != 0 :
            logging.error("nails %s failed with return code %s " % (option, _p.returncode))
            logging.error(''._p.stdout.readlines())
            logging.error(''._p.stderr.readlines())
            return False
        return True    
    except :
        logging.error("'%s' failed with exception" % option)
        return False


def getValidSecondaryActions(_primary_action) :
    """
    Fn to return the valid list of secondary action for given primary action.
    """
    if _primary_action == 'Clean' :
        return ['Block', 'Quarantine','Delete', 'Rename']
    if _primary_action == 'Rename' :
        return ['Block', 'Quarantine', 'Delete']
    if _primary_action == 'Delete' :
        return ['Block', 'Quarantine', 'Delete']
    if _primary_action == 'Quarantine' :
        return ['Block', 'Delete', 'Rename']
    if _primary_action == 'Block' :
        return []
    return []
def createPayload(dir, eicarCount, cleanCount=0) :
    """
    Function to create given number of files in the directory.
    """
    if not os.path.exists(dir) :
        try :
            os.mkdir(dir)
        except :
            logging.error("Failed to create the directory %s" % dir)
            return False
    if cleanCount > 0 :
        logging.debug("Creating clean files")
        for i in range(cleanCount) :
            try :
                fh = open(dir + '/clean-'+ str(i) + '.txt', 'w')
                fh.write("Hello")
                fh.close()
            except :
                logging.error("Failed creating clean files")
                return False
    if eicarCount > 0 :
        logging.debug("Creating eicar files")
        for i in range(eicarCount) :
            if not createEicarInfection(dir+'/eicar-' + str(i) + '.txt'):
                logging.error("Failed creating eicar files")
                return False
    return True
    

def createEicarInfection(file):
    eicarData = "X5O!P%@AP[4\PZX54(P^)7CC)7}$EICAR-STANDARD-ANTIVIRUS-TEST-FILE!$H+H*"
    try:
        fileH = open(file, 'w')
        fileH.writelines(eicarData)
        fileH.close()
        return True 
    except:
        return False

def createInstallCheckInfection(file):
    eicarData = "ZQZXJVBVT"
    try:
        fileH = open(file, 'w')
        fileH.writelines(eicarData)
        fileH.close()
        return True 
    except:
        return False

# Modify this funciton to read default settings from cfg itself.
def resetToDefaults():
    """
    Resets the Scanner to default factory settings.
    NOTE: All OAS, ODS and Exclusions are set to factory settings.
    RETURN : True on success, False otherwise
    """
    default_config = LinuxShieldConfigParser.getProfile(NAILS_CONFIG, 'OAS_default')
    if default_config is None :
        logging.error('Failed to read the default OAS config')
        return False
    if not LinuxShieldConfigParser.setProfile(NAILS_CONFIG, 'OAS', default_config) :
        logging.error('Failed to write the default OAS config')
        return False
    logging.debug("reloading nails...")
    if not nailsStop() :
        logging.error("Failed to stop the nails service")
        return False
    time.sleep(5)
    if not nailsStart() :
        logging.error("Failed to start the nails service")
        return False
    time.sleep(5)
    if not commonOASFns.isOASEnabled() :
        return commonOASFns.enableOAS()
    return True


def getMD5ForFile(file, disableOAS=True):
    """
    Wrapper over the commonFns.getMD5ForFile
    Disables the OAS if it is already enabled before calculating md5
    """
    try:
        _OASState = 0
        if disableOAS and commonOASFns.isOASEnabled() :
            _OASState = 1
            commonOASFns.disableOAS()

        _md5Val = commonFns.getMD5ForFile(file)

        if disableOAS and _OASState == 1:
            enableOAS()

        return _md5Val
    except:
        logging.error("Exception Occured during md5 calculation")
        return None
    logging.error("Final return, None in md5")
    return None

def areAllServicesRunning():
    """
    Fn to check if all VSEL services are running.
    returns 'True' if all services are running. 'False' otherwise.
    """
    for value in ANTIMALWARE_SERVICES :
        if not commonFns.isProcessRunning(value) :
            logging.debug(value + " is not running")
            return False
    return True

def areAllNailsServicesRunning():
    """
    Same as 'areAllServicesRunning()', but 'cma' is not checked.
    """
    for value in NAILS_SERVICES :
        if not commonFns.isProcessRunning(value) :
            logging.debug(value + " is not running")
            return False
    return True


def _isAnyServiceRunning() :
    """
    Private function to check if any of the product service is running
    Used to check if stop service has completed successfully.
    """
    for service in NAILS_SERVICES :
        if commonFns.isProcessRunning(service) :
            logging.debug("Service : %s is running " % service)
            return True
    return False

def isProductInstalled():
    """
    Fn Checks for presense of product in package database, specific product files and directories
    RETURN : True if the product is installed
             False if the product is not installed
    """
    # Change for lower versions of VSEL
    # First get the version Number and then process other things.
    # 1. If could not get product info.. then not installed.
    details = getProductInfo()
    if not details :
        return False
    # For 1.5 and 1.5.1 currently lets only check version and return True.
    if re.search('1\.5', details['version']) :
        return True
    _cmd = ['rpm', '-qa']
    _productsToCheck = ['McAfeeVSEForLinux','MFEcma','MFErt']
    
    if commonFns.getOSDetails()['os_name'] == "Ubuntu" :
        _cmd = ['dpkg', '-l']
        _productsToCheck = ['mcafeevseforlinux', 'mfecma', 'mfert']
    try :
        logging.info("isProductInstalled: Get all packages installed in the system")
        for _product in _productsToCheck :
            _retval = subprocess.call(_cmd + [ _product ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            if _retval != 0 :
                logging.error("isProductInstalled : Unable to get the list of packages")
                return False
    except :
        logging.error("Exception in getting the packages list\n")
        return False
    for _path in PRODUCT_PATHS :
        if not os.path.exists(_path) :
            logging.error(_path + " is not present")
            return False
    return True

def isSyslogEnabled() :
    """
    Fn to check the status of syslog in nails config file.
    return 'True' if logging to syslog is enabled. 'False' otherwise.
    """
    if LinuxShieldConfigParser.getConfigKey(NAILS_CONFIG, 'log.useSyslog') == '0':
        return False
    return True

def enableSyslog() :
    """
    Enables VSEL logging to Syslog.
    return 'True' if logging is enabled successfully. False otherwise.
    """
    if not LinuxShieldConfigParser.setConfig(NAILS_CONFIG, {'log.useSyslog' : '1'}) :
        logging.error('Failed to write into config file.')
        return False
    return nailsReload()

def disableSyslog() :
    """
    Disable VSEL logging to Syslog.
    return 'True' if logging is disabled successfully. False otehrwise
    """
    if not LinuxShieldConfigParser.setConfig(NAILS_CONFIG, {'log.useSyslog' : '0'}) : 
        logging.error('Failed to write into config file.')
        return False
    return nailsReload()

def getSyslogLevel() :
    """
    returns the sysLogDetillevel of nails config file.
    """
    return  LinuxShieldConfigParser.getConfigKey(NAILS_CONFIG, 'log.syslogDetailLevel')

def setLogLevel(level) :
    """
    Sets the log.detailLevel value of nails.cfg file.
    returns 'True' if the value is set successfully. 'False' otherwise
    """
    if not LinuxShieldConfigParser.setConfig(NAILS_CONFIG, {'log.detailLevel' : level}) : 
        logging.error('Failed to write into config file.')
        return False
    return nailsReload()

def getLogLevel() :
    """
    returns the 'log.detailLevel' value of nails.cfg
    """
    return  LinuxShieldConfigParser.getConfigKey(NAILS_CONFIG, 'log.detailLevel')


def setSyslogLevel(level):
    """
    Sets the syslogDetailLevel for nails.cfg
    returns 'True' if value is successfully set. 'False' otherwise.
    """
    if not isSyslogEnabled() :
        if not enableSyslog() :
            return False
    if not LinuxShieldConfigParser.setConfig(NAILS_CONFIG, {'log.syslogDetailLevel' : level}) :
        logging.error('Failed to write into config file.')
        return False
    return nailsReload()


def searchSchedule(pattern, field = 'taskName'):
    """
    Fn to search scanLog for given field
    """
    logging.debug("searchSchedule : Getting the db records that match ")
    _matched_records = searchDBLog(readSchedule, pattern, field, SCHEMA_SCHEDULE)
    if _matched_records is None or len(_matched_records) == 0 :
        logging.debug("No matching record found for %s in field %s" % (pattern, field))
        return False
    return True


def searchScanLog(pattern, field = 'action'):
    """
    Fn to search scanLog for given field
    """
    _matched_records = searchDBLog(readScanLog, pattern, field, SCHEMA_SCANLOG)
    if _matched_records is None or len(_matched_records) == 0 :
        return False
    return True
def searchEventLog(pattern, field = 'description') :
    """
    Fn to search eventLog for specific pattern.
    @return True if pattern is found. False otherwise.
    """
    _matched_records = searchDBLog(readEventLog, pattern, field, SCHEMA_EVENTLOG)
    if _matched_records is None or len(_matched_records) == 0 :
        return False
    return True

def searchDBLog(readLog, pattern, field, schema) :
    """
    Private Fn to read all records from given table and then 
    search if the given pattern is matching in the records.
    """
    if readLog is None :
        logging.error("Callback funtion must be provided")
        return None
    if pattern is None or not isinstance(pattern, str) or len(pattern) == 0 :
        logging.error("pattern must be provided and must be a non empty string")
        return None
    if field is None or not isinstance(field, str) or len(field) == 0 :
        logging.error("field must be provided and must be a non empty string")
        return None
    if field not in schema :
        loging.error("%s is not a valid column to search in eventLog" % field)
        return None
    logging.debug("Reading all records from table")
    _records = readLog()
    if _records is None :
        logging.error("No records are found")
        return False
    _matched_records = []
    for _record in _records :
        if re.search(pattern, _record[field]) is not None :
            logging.debug("Match found : %s" % _record[field])
            _matched_records.append(_record)
    return _matched_records


def readEventLog() :
    """
    Fn to read the eventLog table from NAILS_DB and return the rows 
    as list of dictionaries.
    """
    return _listToDict(_readNailsTable('eventLog'), SCHEMA_EVENTLOG)
            

def readSchedule() :
    """
    Fn to read all records from 'schedule' table
    """
    return _listToDict( _readNailsTable('schedule'), SCHEMA_SCHEDULE)

def readScanLog() :
    """
    Fn to read all records of the scan log.
    """

    return _listToDict( _readNailsTable('scanLog'), SCHEMA_SCANLOG)

def constructCronEntry(timeTable) :
    _l_entry = [ '0', '0', '*', '*', '*']

    _l_entry[0] =  timeTable['minute']
    _l_entry[1] = timeTable['hour']
    if timeTable['type'] == 'once' :
        _l_entry[2] = timeTable['day']
        _l_entry[3] = timeTable['month']

    elif timeTable['type'] == 'weekly' :
        _l_entry[4] = timeTable['days']

    elif timeTable['type'] == 'monthly' :
        _l_entry[4] = timeTable['day']
    logging.debug("Cron entry created is %s" % ' '.join(_l_entry))
    return ' '.join(_l_entry)


def writeCrontabEntry(entry, taskId) :
    """
    Writes an entry into /etc/crontab
    """
    _lines = []
    if os.path.exists('/etc/crontab') :
        _fh = open('/etc/crontab', 'r')
        if _fh is None :
            logging.error("Failed to open crontab")
            return False
        _lines = _fh.readlines()
        _fh.close()
    _line = entry + ' root ' + NAILS + ' runsched ' + str(taskId) + "\n"

    # Check if the entry is already present
    _tasks_section = False
    for _i in range(len(_lines)) :
        if re.search('McAfeeVSEForLinux SCHEDULED TASK INFORMATION FOLLOWS', _lines[_i] ) :
            _tasks_section = True
        if not _tasks_section :
            continue
        # If any matching entry is found then replace with correct entry
        if re.search('nails\s+runsched\s+' + str(taskId), _lines[_i]) is not None :
            _lines[_i] = _line
            break
        # If we reached end of section and do not find any schedule we need to add one and
        # break
        if re.search('END OF McAfeeVSEForLinux SCHEDULED TASK INFORMATION', _lines[_i]) :
            logging.debug("Inserting the line before the end line")
            _lines.insert(_i, _line)
            break
    else :
        _lines.append(_line)
    _fh = open('/etc/crontab.TMP', 'w')
    for _line in _lines :
        _fh.write(_line)
    _fh.close()

    try :
        logging.debug("Now moving the file")
        shutil.move('/etc/crontab.TMP', '/etc/crontab')
    except :
        logging.error("Exception occured writing the crontab")
        return False
    return True

def deleteCrontabEntry(taskId) :
    _lines = []
    if not os.path.exists('/etc/crontab') :
        logging.error("file /etc/crontab does not exist")
        return False

    _fh = open('/etc/crontab', 'r')
    if _fh is None :
        logging.error("Failed to open crontab")
        return False
    _lines = _fh.readlines()
    _fh.close()
    # Check if the entry is already present
    _regex = 'nails\s+runsched\s+' + str(taskId)
    for _i in range(len(_lines)) :
        if re.search(_regex, _lines[_i]) is not None :
            # Pop out the first entry and break
            logging.debug("Deleting the cron entry : " +_lines[_i])
            _lines.pop(_i)
            break
    else :
        logging.error("Entry not found  in crontab")
        return False
    _fh = open('/etc/crontab.TMP', 'w')
    for _line in _lines :
        _fh.write(_line )
    _fh.close()

    try :
        logging.debug("Now moving the file")
        shutil.move('/etc/crontab.TMP', '/etc/crontab')
    except :
        logging.error("Exception occured writing the crontab")
        return False
    return True


def getScheduleMaxId() :
    """
    Function to return the maximum i_taskId number from the schedule table.
    it simply runs 'select max(i_taskId) from schedule' and returns the number.
    returns 0 if any error occurs.
    """
    _query = 'select max(i_taskId) from schedule'
    try :
        logging.debug("Running query %s" % _query)
        _p = subprocess.Popen([SQLITE, NAILS_DB, _query], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if _p is None :
            logging.error("Failed to create the sqlite process")
            return 0
        _p.wait()
        _lines = _p.stdout.readlines()
        if len(_lines) == 0 :
            return 1
        _line = _lines[0].rstrip().lstrip().rstrip("\n")
        if _line.isdigit() :
            return int(_line)
        logging.error("Output from sqlite query is not a number")
        return 0
    except ValueError:
        logging.error("Query did not return number %s " % _line)
        return 0
    except :
        logging.error("Exception occured when getting the max count for taskId")
        return 0

def getTaskResult(taskName) :
    """
    Fn to return the result dictionary for the given taskname :
    """
    _matched_records = searchDBLog(readSchedule, taskName, 'taskName', SCHEMA_SCHEDULE)
    if _matched_records is None or len(_matched_records) == 0 :
        return 0
    logging.debug("Record found. fetching results")
    _d_taskResult = dict()
    _s_taskResult = _matched_records[0]['taskResults']
    for item in _s_taskResult.split(',') :
        (_val, _key) = item.split(' ')
        _val.lstrip().rstrip()
        _key.lstrip().rstrip().rstrip("\n")

        _d_taskResult[_key] = _val
    return _d_taskResult

def getTaskStatus(taskName) :
    """
    Function to get the status of given Ondemand task
    """
    _query = 'select status from schedule where taskName = "' + taskName + '"'
    try :
        _p = subprocess.Popen([SQLITE, NAILS_DB, _query], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if not _p :
            logging.error("Query failed with error code : %d" % _status)
            logging.debug("Deleting the config profile for rollback")
            if not LinuxShieldConfigParser.deleteProfile(ODS_CONFIG, profileName) :
                logging.error("Failed to delete the profile %s " % profileName)
            return False
        _p.wait()

        _lines = _p.stdout.readlines()
        if len(_lines) == 0 :
            logging.error("No record found")
            return None
        return _lines[0].rstrip().lstrip().rstrip("\n")
    except :
        logging.error("Exception getting the taskStatus")
        return None

def deleteTask(conditions) :
    """
    Fn to delete a row from table 'schedule' that match all the conditions specified.
    """   
    if conditions is None or not isinstance(conditions, dict) or len(conditions) == 0 :
        logging.error('"conditions" dictionary cannot be empty')
        return False
    _query = 'delete from schedule where ' 
    for field, value in conditions.items() :
        if field not in SCHEMA_SCHEDULE :
            logging.error("'field' must be a valid column name")
            return False

        if field in [ 'i_taskId', 'i_lastRun', 'i_duration', 'i_nextRun', 'i_recurrenceCounter', 'i_taskPid'] :
            _query = _query + field + ' = ' + value + ' and '
        else :
            _query = _query + field + ' = "' + value + '" and '

    if _query.endswith(' and ') :
        _query = _query[0:len(_query) - len(' and ')]

    try :
        logging.debug("Deleting the rows from table %s" % _query)
        _cmd = [SQLITE, NAILS_DB, _query]
        _p = subprocess.Popen(_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if _p is None :
            logging.error("Failed to create sqlite process")
            return None
        _p.wait()
        if _p.returncode != 0 :
            logging.error("sqlite returned with code %s " % _p.returncode)
            logging.error("The STDERR IS :" + "\n".join( _p.stderr.readlines()))
            return None
        return True
    except :
        logging.error("_readNailsTable failed with exception")
        return False 

def getTaskTimeTable(timeTable) :
    """
    private function to construct a timeTable string from the provided dict
    return string representation of given timeTable.
    None is returned on any error.
    """
    _type = timeTable.pop('type')
    s_timeTable = 'type=' + _type
    valid_keys = []
    if _type == 'once' :
        valid_keys =  ['day', 'month', 'year', 'hour', 'minute']
    elif _type == 'daily' :
        valid_keys = ['recurrence', 'hour', 'minute'] 
    elif _type == 'weekly' :
        valid_keys = ['recurrence', 'hour', 'minute', 'days']
    elif _type == 'monthly' :
        valid_keys = ['week', 'day', 'hour', 'minute', 'months']
    for key in valid_keys :
        if not timeTable.has_key(key) :
            logging.error("schedule require the value for %s" % key)
            return None
        if timeTable[key] is None or not isinstance(timeTable[key], str) or re.search('^(\d+;?)+$', timeTable[key]) is None :
            logging.error("Invalid value for %s" % key)
            return None
        s_timeTable = s_timeTable + ',' + key + '=' + timeTable[key]
    return s_timeTable


def createUpdateTask(taskName, timeTable=None, updateEngine=True) :
    """
    Create the scheduled update

    # Record for once type :
    # 7|update 7|type=once,day=25,month=7,year=2010,hour=14,minute=0|Update|toUpdate=dat;engine|||Idle||||0|
    # ANalysis : To create scheduled upate.
    # Record for Immediate Task
    # 4|update 4|type=unscheduled|Update|toUpdate=dat;engine|Update in Progress|1279947114|
    # Running|Downloading 60516052avv.gem.|6||0|
    # Record for Unscheduled Task
    # 5|update 5|type=unscheduled|Update|toUpdate=dat|||Idle||||0|
    # Analysis : It is observed that when I add the record. it works for update
    # 
    #################
    # 1. ODS for every 3 days
    # 1. /home/bubble to scan and /proc is not under exclusion.
    # 1. /var/opt is excluded 
    #  /opt/NAI is excluded but not subdirectories
    # 3|on-demand scan 3|type=daily,recurrence=300,hour=12,minute=0|On-Demand|profileName=ODS_3,paths=path:/home/bubble;exclude:false|||Idle|||||
    ### McAfeeVSEForLinux SCHEDULED TASK INFORMATION FOLLOWS.  DO NOT EDIT THIS SECTION. ###
    # 0 0 * * * root /opt/NAI/LinuxShield/bin/nails runsched 1
    # 0 12 * * * root /opt/NAI/LinuxShield/bin/nails runsched 3
    ### END OF McAfeeVSEForLinux SCHEDULED TASK INFORMATION. ###
    # 4|on-demand scan 4|type=daily,recurrence=4,hour=13,minute=0|On-Demand|profileName=ODS_4,paths=path:/var;exclude:false|path:/opt;exclude:true|||Idle|||||
    #################
    """
    if taskName is None or not isinstance(taskName, str) :
        logging.error("Argument 'taskName' must be a string")
        return False
    if timeTable is None :
        timeTable = {'type' : 'unscheduled' }
    if not isinstance(timeTable,dict) or len(timeTable) == 0 :
        logging.error("Argument 'timeTable' must be a dict")
        return False
    if not timeTable.has_key('type') or timeTable['type'] not in ['unscheduled', 'once', 'daily', 'weekly', 'monthly'] :
        logging.error("invalid value for 'type' in timeTable")
        return False
    if searchSchedule(taskName, 'taskName') :
        logging.error("TaskName %s is already existing" % taskName)
        return False

    s_timeTable = getTaskTimeTable(dict(timeTable))
    if s_timeTable is None :
        return False
    # Find the latest taskId and add one.
    _i_taskId = getScheduleMaxId()
    if _i_taskId <= 0 :
        logging.error("Invalid number %d returned as max taskId" % _i_taskId)
        logging.debug("Trying to rollback the profile addition activity")
        if not LinuxShieldConfigParser.deleteProfile(ODS_CONFIG, profileName) :
            logging.error("Failed to rollback the profile addition activity")
        return False

    # Add one to latest taskId and then create the task
    _i_taskId = _i_taskId + 1
    if updateEngine :
        updateEngine = ';engine'

    # Add scheduled task
    _query = 'insert into schedule (i_taskId, taskName, timetable, taskType, taskInfo, status) ' +\
             'values (' + str(_i_taskId) + ', ' +\
                    '"' + taskName + '", ' +\
                    '"' + s_timeTable + '", "Update", ' + '"toUpdate=dat' + updateEngine + '", "Idle")' 
                    
    logging.debug("Inserting record : %s" % _query)
    try :
        _status = subprocess.call([SQLITE, NAILS_DB, _query], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if _status != 0 :
            logging.error("Query failed with error code : %d" % _status)
            return False
        # Query to see if task exist or not.
        logging.debug("Searching if the taskName exist in database")
        if not searchSchedule(taskName) :
            logging.error("Though sqlite returned 0, the record is not added in database")
            return False
    except :
        logging.error("Exception occured during creation of record.")
        return False
    
    if timeTable['type'] in ['once', 'daily', 'weekly', 'monthly'] :
        entry = constructCronEntry(timeTable)   
        taskId = getScheduleId(taskName)
        if not writeCrontabEntry(entry, taskId) :
            logging.error("Failed to write entry %s into crontab" % entry)
            if not deleteTask({'taskName':taskName, 'taskType':'Update'}) :
                logging.error("Failed to remove the row from table")
            return False
    return True

def deleteUpdateTask(taskName) :
    """
    Deletes an unscheduled update Task from the database
    """
    if taskName is None or not isinstance(taskName, str) :
        logging.error('"field" is must and should be a valid column name')
        return False

    _query = 'delete from schedule where taskType = "Update" and taskName = "' + taskName  + '"'
    try :
        _cmd = [SQLITE, NAILS_DB, _query]
        logging.debug("Deleting the rows from table %s" % _query)
        _p = subprocess.Popen(_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if _p is None :
            logging.error("Failed to create sqlite process")
            return False
        _p.wait()
        if _p.returncode != 0 :
            logging.error("sqlite returned with code %s " % _p.returncode)
            logging.error("The STDERR IS :" + "\n".join( _p.stderr.readlines()))
            return False
    except :
        logging.error("_readNailsTable failed with exception")
        return False
    return True

def runTask(taskName):
    """
    Fn to run the specific task
    """
    logging.debug("Getting the Id for the taskName %s" % taskName)
    taskId = getScheduleId(taskName)
    if taskId < 1 :
        logging.error("Failed to get the Id for the taskName %s " % taskName)
    logging.debug("Running task with id : %d" % taskId)
    try :
        _p = subprocess.Popen([NAILS, 'task', '--run', str(taskId)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if _p is None :
            logging.error("Failed to create process")
            return False
        _p.wait()
        _stdout = _p.stdout.readlines()
        _stderr = _p.stderr.readlines()
        if _p.returncode != 0 :
            logging.error("task returned %d" % _p.returncode)
            logging.error(''.join(_stdout))
            logging.error(''.join(_stderr))
            return False
        return True
    except :
        logging.error("Exception occured while running the task")
        return False

def getScheduleId(taskName) :
    """
    Fn to return the id (as int) for the given taskName.
    """
    _matched_records = searchDBLog(readSchedule, taskName, 'taskName', SCHEMA_SCHEDULE)
    if _matched_records is None or len(_matched_records) == 0 :
        return 0
    logging.debug("taskId for given taskName is : %s " % _matched_records[0]['i_taskId'])
    return int(_matched_records[0]['i_taskId'])


    


def _listToDict(table, schema) :
    if table is None :
        return None

    _new_table = []
    for _row in table :
        _d = dict()
        if len(schema) != len(_row) :
            logging.error("Mismatch of number of fields in schema to number of fields in row")
            return _new_table
        for i in range(len(_row)) :
            _d[ schema[i] ] = _row[i]
        _new_table.append(_d)
    return _new_table

        
def _readNailsTable(table) :
    """
    Fn to read the given table from NAILS_DB and return the rows.
    @param table - name of the table whose rows need to be fetched
    @return list - containing the rows of the table, where each
                   element of list is a list of columns
    """
    if table is None or not isinstance(table, str) :
        logging.error("Table name must be provided as string")
        return False

    try :
        _cmd = [SQLITE, NAILS_DB, 'select * from ' + table]
        logging.debug("Getting the rows from table %s" % table)
        _p = subprocess.Popen(_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if _p is None :
            logging.error("Failed to create sqlite process")
            return None
        _p.wait()
        if _p.returncode != 0 :
            logging.error("sqlite returned with code %s " % _p.returncode)
            logging.error("The STDERR IS :" + "\n".join( _p.stderr.readlines()))
            return None
        _stdout = _p.stdout.readlines()
        _table = []
        for _line in _stdout :
            _tuple = _line.split('|')
            _table.append(_tuple)
        return _table
    except :
        logging.error("_readNailsTable failed with exception")
        return False

def clearQuarantine():
    """
    Clears the quarantine
    RETURN : True if successfully cleared. False otherwise
    """
    # Find the quarantine directory
    _quarantine_dir = LinuxShieldConfigParser.getConfigKey(NAILS_CONFIG, 'nailsd.profile.OAS.quarantineDirectory')
    if not os.path.exists(_quarantine_dir) :
        logging.debug("Quarantine directory %s does not exist. Nothing to clean" % _quarantine_dir)
        return True
    try :
        _retval = subprocess.call(['rm' , '-rf', _quarantine_dir + '/*'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if _retval != 0 :
            logging.error("rm -rf on quarantine returned code %s " % _reval)
            return False
        return True
    except :
        logging.error("Failed to do rm on quarantine")
        return False

def isFileQuarantined(filename) :
    """
    Fn to check if the filepath given exist in the quarantine list.
    @return True if file is found in quarantine. False otherwise.
    """
    if filename is None or not isinstance(filename, str) :
        logging.error("commonAntiMalwareFns.isFileQuarantined : filename must be provided as string")
        return False
    filepath = os.path.abspath(filename)
    _quarantine_list = _getQuarantinedFiles()
    if not _quarantine_list :
        logging.error("Could not retrieve quarantine list")
        return False
    for _q in _quarantine_list :
        if _q['destination_file'] == filepath :
            return True
    return False

def _getQuarantineMetaFile(filename) :
    """
    Private Fn to return the metafile name for the given filename
    """
    if filename is None or not isinstance(filename, str) :
        logging.error("commonAntiMalwareFns._getQuarantineMetaFile: filename must be provided as string")
        return False
    filepath = os.path.abspath(filename)
    _quarantine_list = _getQuarantinedFiles()
    for _q in _quarantine_list :
        if _q['destination_file'] == filepath :
            return _q['meta_file']
    return False
    
def _getQuarantinedFiles() :
    """
    Private Fn to read the quarantine and store records in the list
    """
    try :
        _p = subprocess.Popen([NAILS, 'quarantine' , '--list'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if _p is None :
            logging.error("Failed to start the process")
            return None
        _p.wait()
        if _p.returncode != 0 :
            logging.error("Quarantine listing failed with return code %s." % _p.returncode)
            return None
        _lines = _p.stdout.readlines()
        _quarantine_list = []
        for _line in _lines :
            _m = re.search('^(.*?):\s*(.*)$', _line)
            if _m is not None :
               _entry = {'meta_file':_m.group(1), 'destination_file':_m.group(2)}
               _quarantine_list.append(_entry)
        return _quarantine_list
    except :
        logging.error("commonAntiMalwareFns._getQuarantineFiles : failed with exception")
        return None

#TO fix for process wait 
# Need to include the code written by sundeep to wait for update process to complete

def runUpdate():
    """
    Starting the manual update
    """
    _taskName = 'LinuxShield Update'
    try:
        logging.debug("Running task")
        if not runTask(_taskName) :
            logging.error("Failed to run task %s" % _taskName)
            return False
        # Wait till the task is complete
        logging.debug("Waiting for task to complete.")
        while True :
            time.sleep(30)
            status = getTaskStatus(_taskName)
            logging.debug("Status of Update is : %s" % status)
            if status not in ['Running' ] :
                break
        status = getTaskResult(_taskName)
        return True

    except:
        logging.error('Manual Update Failed with exception')
        return False


def replaceDat(datPath):
    """
    Copying old dat 
    """
    files = ['avvclean.dat',  'avvnames.dat',  'avvscan.dat']
    try:
        for f in files :
            logging.debug("Copying %s to %s" % (datPath + '/' + f, DAT_PATH))
            shutil.copy(datPath + '/' + f, DAT_PATH)
        #Restrting the nails service after dat copy
        if not nailsStop() :
            logging.error ('Not able to stop nails service after dat copy')
            return False
        if not nailsStart() :
            logging.error ('Not able to start nails service after dat copy')
            return False
        return True
    except:
        logging.error('dat copy failed with exception')
        return False


def GetEngineVersion():   
    """
    Engine version  
    """
    try:
        _cmd = ['/opt/NAI/LinuxShield/bin/nails','-v']
        _p= subprocess.Popen(_cmd,stdout=subprocess.PIPE,stderr=subprocess.PIPE)
        if _p is None :
             logging.error('Unable to create process')
             return False
        _p.wait()
        _value = _p.stdout.readlines()[2]
        _enginever = re.search('(\d+)\.(\d+)',_value)
        return _enginever.group(1)

    except:
        logging.error('Not able to get the engine version')
        return False


def GetDatVersion():   
    """
    Dat version  
    """
    try:
        _cmd = ['/opt/NAI/LinuxShield/bin/nails','-v']
        _p= subprocess.Popen(_cmd,stdout=subprocess.PIPE,stderr=subprocess.PIPE)
        if _p is None :
             logging.error('Unable to create process')
             return False
        _p.wait()
        _value = _p.stdout.readlines()[1]
        _datversion = re.search('(\d+)\.',_value)
        return _datversion.group(1)

    except:
        logging.error('Not able to get the dat version')
        return False

def getProductInfo() :
    """
    """
    if not os.path.exists(NAILS) :
        logging.error("%s does not exists" % NAILS)
        return None
    re_map = dict()
    re_map['\s+(\d+\.\d+\.\d+)-(\d+)']                     = ['version', 'build']
    re_map['Virus\s+definition\s+files\s+(\d+\.\d+)']      = ['dat_version']
    re_map['Virus\s+scanning\s+engine\s+(\d+\.\d+)']       = ['engine_version']
    re_map['Virus\s+scanning\s+engine\s+API\s+(\d+\.\d+)'] = ['engine_api']
    
    try :
        print NAILS
        _p = subprocess.Popen([NAILS, '-v'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        _p.wait()
        _lines = _p.stdout.readlines()
        _product_info = dict()
        for _line in _lines :
            for regex in re_map.keys() :
                m = re.search(regex, _line)
                if m is None :
                    continue
                vals = re_map[regex]
                for i in xrange(0, len(vals)) :
                    _product_info[vals[i]] = m.group(i+1)
        return _product_info
    except :
        logging.error("Not able to run the command")
        return None

def UnInstallPackage():
    """
    UnInstallation of VSEL pacakges
    """
    _value = commonFns.getOSDetails()
    _packagename = ['McAfeeVSEForLinux','MFEcma','MFErt']
    
    if _value['os_name'] is 'Ubuntu' :
        _packagename = ['mcafeevseforlinux','mfecma','mfert']
    
    try :
        for _package in _packagename :
            logging.debug("Uninstalling package %s" % _package)
            if not commonFns.UnInstall(_package) :
                logging.error('Uninstalation failed')
                return False
        logging.info('Uninstallation passed')
        return True
    except:
        logging.error('Uninstallation failed with exception')
        return False


#def InstallPackage(buildpath):
#    """
#    Installting the VSEL pacakges
#    """
#    if not os.path.exists(buildpath) :
#        logging.error("File %s does not exist" % buildpath)
#        return False
#    
#    logging.debug("Extracting %s " % self._filepath)
#
#    if not commonFns.extractArchive(self._filepath, self._destination) :
#        logging.error("tar file extraction failed")
#        return 1
    
#    _value = commonFns.getOSDetails()
#    _packagename = ['MFErt.i686.rpm','MFEcma.i686.rpm','McAfeeVSEForLinux-1.6.0*.rpm']
    
#    if _value['os_name'] is 'Ubuntu' :
#        _packagename = ['MFErt.i686.deb','MFEcma.i686.deb','McAfeeVSEForLinux-1.6.0*.deb']

#    try :
#        for _package in _packagename :
#            logging.debug("Installing package " + buildpath + ' ' + _package)
#            if commonFns.Install(buildpath, _package) != True :
#                logging.error('Installation failed')
#                return False
#
#            time.sleep(10)
#        logging.info( 'Installation passed')
#        return True

#    except:
#        logging.error('Installation failed with exception')

